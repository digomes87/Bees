#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
An√°lise Principal do Comportamento de Abelhas e Mudan√ßas Clim√°ticas.

Este m√≥dulo implementa a an√°lise explorat√≥ria completa dos dados de abelhas
e vari√°veis clim√°ticas na Am√©rica do Sul, seguindo metodologia cient√≠fica rigorosa.

Autor: Diego Gomes
Data: 2024
Projeto: Bee Climate Analysis
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import logging
import warnings
from pathlib import Path
from typing import Dict, List, Tuple, Optional

# Imports locais
from config import (
    DATA_CONFIG, ANALYSIS_CONFIG, VISUALIZATION_CONFIG, 
    LOGGING_CONFIG, RESULTS_DIR, IMAGES_DIR, PROCESSED_DATA_DIR
)

# Configurar warnings e logging
warnings.filterwarnings('ignore')
logging.basicConfig(**LOGGING_CONFIG)
logger = logging.getLogger(__name__)

class BeeClimateAnalyzer:
    """
    Classe principal para an√°lise do impacto das mudan√ßas clim√°ticas 
    no comportamento de abelhas na Am√©rica do Sul.
    """
    
    def __init__(self):
        """
        Inicializa o analisador com configura√ß√µes padr√£o.
        """
        self.data = None
        self.climate_data = None
        self.bee_data = None
        self.results = {}
        
        # Configurar estilo de visualiza√ß√£o
        plt.style.use(VISUALIZATION_CONFIG['PLOT_STYLE'])
        sns.set_palette(VISUALIZATION_CONFIG['COLOR_PALETTE'])
        plt.rcParams['figure.figsize'] = VISUALIZATION_CONFIG['FIGURE_SIZE']
        plt.rcParams['savefig.dpi'] = VISUALIZATION_CONFIG['DPI']
        
        logger.info("BeeClimateAnalyzer inicializado")
    
    def load_data(self, data_path: Optional[str] = None) -> pd.DataFrame:
        """
        Carrega dados de abelhas e clima.
        
        Args:
            data_path (str, optional): Caminho para arquivo de dados personalizado
        
        Returns:
            pd.DataFrame: Dados carregados e processados
        """
        logger.info("Iniciando carregamento de dados...")
        
        if data_path and Path(data_path).exists():
            self.data = pd.read_csv(data_path)
            logger.info(f"Dados carregados de: {data_path}")
        else:
            # Gerar dados simulados para demonstra√ß√£o
            self.data = self._generate_sample_data()
            logger.info("Dados simulados gerados para demonstra√ß√£o")
        
        # Processar e limpar dados
        self.data = self._preprocess_data(self.data)
        
        # Separar dados clim√°ticos e de abelhas
        self._separate_data_types()
        
        logger.info(f"Dados carregados: {len(self.data)} registros")
        return self.data
    
    def _generate_sample_data(self) -> pd.DataFrame:
        """
        Gera dados simulados realistas para demonstra√ß√£o.
        
        Returns:
            pd.DataFrame: Dados simulados
        """
        np.random.seed(42)
        
        # Configura√ß√µes temporais
        start_year = DATA_CONFIG['SAMPLING']['START_YEAR']
        end_year = DATA_CONFIG['SAMPLING']['END_YEAR']
        years = np.arange(start_year, end_year + 1)
        n_years = len(years)
        
        # Gerar dados para m√∫ltiplas regi√µes
        regions = ['Norte', 'Nordeste', 'Centro-Oeste', 'Sudeste', 'Sul']
        data_list = []
        
        for region in regions:
            # Dados clim√°ticos com tend√™ncias realistas
            base_temp = {'Norte': 26.5, 'Nordeste': 25.8, 'Centro-Oeste': 24.2, 
                        'Sudeste': 22.1, 'Sul': 19.8}[region]
            
            temp_trend = np.linspace(0, 2.8, n_years)  # Aquecimento de 2.8¬∞C
            temperature = base_temp + temp_trend + np.random.normal(0, 0.6, n_years)
            
            # Precipita√ß√£o com variabilidade
            base_precip = {'Norte': 2200, 'Nordeste': 800, 'Centro-Oeste': 1400,
                          'Sudeste': 1300, 'Sul': 1600}[region]
            
            precip_trend = np.linspace(0, -150, n_years)  # Redu√ß√£o de chuvas
            precipitation = base_precip + precip_trend + np.random.normal(0, 100, n_years)
            precipitation = np.maximum(precipitation, 300)  # M√≠nimo de 300mm
            
            # Dados de abelhas
            base_abundance = {'Norte': 85, 'Nordeste': 65, 'Centro-Oeste': 75,
                             'Sudeste': 70, 'Sul': 60}[region]
            
            abundance_decline = np.linspace(0, -20, n_years)  # Decl√≠nio de abund√¢ncia
            bee_abundance = base_abundance + abundance_decline + np.random.normal(0, 5, n_years)
            bee_abundance = np.maximum(bee_abundance, 20)  # M√≠nimo de 20
            
            # Diversidade de esp√©cies
            base_diversity = {'Norte': 45, 'Nordeste': 35, 'Centro-Oeste': 40,
                             'Sudeste': 38, 'Sul': 32}[region]
            
            diversity_decline = np.linspace(0, -8, n_years)
            species_diversity = base_diversity + diversity_decline + np.random.normal(0, 2, n_years)
            species_diversity = np.maximum(species_diversity, 15)
            
            # Produ√ß√£o de mel
            base_honey = {'Norte': 28, 'Nordeste': 22, 'Centro-Oeste': 26,
                         'Sudeste': 24, 'Sul': 30}[region]
            
            honey_decline = np.linspace(0, -6, n_years)
            honey_production = base_honey + honey_decline + np.random.normal(0, 2, n_years)
            honey_production = np.maximum(honey_production, 12)
            
            # Coordenadas geogr√°ficas aproximadas
            region_coords = {
                'Norte': (-3.0, -60.0),
                'Nordeste': (-9.0, -40.0),
                'Centro-Oeste': (-15.0, -56.0),
                'Sudeste': (-20.0, -44.0),
                'Sul': (-27.0, -51.0)
            }
            
            lat, lon = region_coords[region]
            
            # Criar DataFrame para a regi√£o
            region_data = pd.DataFrame({
                'year': years,
                'region': region,
                'latitude': lat + np.random.normal(0, 1, n_years),
                'longitude': lon + np.random.normal(0, 2, n_years),
                'temperature': temperature,
                'precipitation': precipitation,
                'bee_abundance': bee_abundance,
                'species_diversity': species_diversity,
                'honey_production': honey_production
            })
            
            data_list.append(region_data)
        
        return pd.concat(data_list, ignore_index=True)
    
    def _preprocess_data(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        Preprocessa e limpa os dados.
        
        Args:
            data (pd.DataFrame): Dados brutos
        
        Returns:
            pd.DataFrame: Dados processados
        """
        logger.info("Iniciando preprocessamento dos dados...")
        
        # Converter year para datetime
        data['date'] = pd.to_datetime(data['year'], format='%Y')
        
        # Criar vari√°veis derivadas
        data['temperature_anomaly'] = data.groupby('region')['temperature'].transform(
            lambda x: x - x.mean()
        )
        
        data['precipitation_anomaly'] = data.groupby('region')['precipitation'].transform(
            lambda x: x - x.mean()
        )
        
        # Calcular √≠ndices compostos
        data['climate_stress_index'] = (
            data['temperature_anomaly'].abs() + 
            data['precipitation_anomaly'].abs()
        ) / 2
        
        data['bee_health_index'] = (
            data['bee_abundance'] * 0.4 + 
            data['species_diversity'] * 0.3 + 
            data['honey_production'] * 0.3
        )
        
        # Remover outliers extremos
        numeric_columns = data.select_dtypes(include=[np.number]).columns
        for col in numeric_columns:
            Q1 = data[col].quantile(0.01)
            Q3 = data[col].quantile(0.99)
            data[col] = data[col].clip(lower=Q1, upper=Q3)
        
        logger.info("Preprocessamento conclu√≠do")
        return data
    
    def _separate_data_types(self):
        """
        Separa dados clim√°ticos e de abelhas para an√°lises espec√≠ficas.
        """
        climate_cols = ['year', 'region', 'latitude', 'longitude', 'date',
                       'temperature', 'precipitation', 'temperature_anomaly', 
                       'precipitation_anomaly', 'climate_stress_index']
        
        bee_cols = ['year', 'region', 'latitude', 'longitude', 'date',
                   'bee_abundance', 'species_diversity', 'honey_production', 
                   'bee_health_index']
        
        self.climate_data = self.data[climate_cols].copy()
        self.bee_data = self.data[bee_cols].copy()
    
    def analyze_temporal_patterns(self) -> Dict:
        """
        Analisa padr√µes temporais nos dados.
        
        Returns:
            Dict: Resultados da an√°lise temporal
        """
        logger.info("Iniciando an√°lise de padr√µes temporais...")
        
        results = {}
        
        # An√°lise de tend√™ncias por regi√£o
        trends = {}
        for region in self.data['region'].unique():
            region_data = self.data[self.data['region'] == region]
            
            # Calcular tend√™ncias lineares
            temp_trend = np.polyfit(region_data['year'], region_data['temperature'], 1)[0]
            precip_trend = np.polyfit(region_data['year'], region_data['precipitation'], 1)[0]
            bee_trend = np.polyfit(region_data['year'], region_data['bee_abundance'], 1)[0]
            
            trends[region] = {
                'temperature_trend': temp_trend,
                'precipitation_trend': precip_trend,
                'bee_abundance_trend': bee_trend
            }
        
        results['regional_trends'] = trends
        
        # An√°lise de sazonalidade (simulada)
        seasonal_patterns = self._analyze_seasonal_patterns()
        results['seasonal_patterns'] = seasonal_patterns
        
        # Detec√ß√£o de pontos de mudan√ßa
        change_points = self._detect_change_points()
        results['change_points'] = change_points
        
        self.results['temporal_analysis'] = results
        logger.info("An√°lise temporal conclu√≠da")
        
        return results
    
    def _analyze_seasonal_patterns(self) -> Dict:
        """
        Analisa padr√µes sazonais (simulado para dados anuais).
        
        Returns:
            Dict: Padr√µes sazonais identificados
        """
        # Para dados anuais, simular varia√ß√£o sazonal
        seasonal_data = {}
        
        for region in self.data['region'].unique():
            region_data = self.data[self.data['region'] == region]
            
            # Simular varia√ß√£o sazonal baseada na latitude
            lat = region_data['latitude'].mean()
            
            # Regi√µes mais ao norte t√™m menor varia√ß√£o sazonal
            seasonal_amplitude = max(0.5, abs(lat) * 0.1)
            
            seasonal_data[region] = {
                'temperature_seasonality': seasonal_amplitude,
                'precipitation_seasonality': seasonal_amplitude * 1.5,
                'bee_activity_seasonality': seasonal_amplitude * 0.8
            }
        
        return seasonal_data
    
    def _detect_change_points(self) -> Dict:
        """
        Detecta pontos de mudan√ßa significativa nas s√©ries temporais.
        
        Returns:
            Dict: Pontos de mudan√ßa detectados
        """
        change_points = {}
        
        for region in self.data['region'].unique():
            region_data = self.data[self.data['region'] == region].sort_values('year')
            
            # Detectar mudan√ßas usando diferen√ßas de segunda ordem
            temp_diff = np.diff(region_data['temperature'], n=2)
            bee_diff = np.diff(region_data['bee_abundance'], n=2)
            
            # Identificar anos com mudan√ßas significativas
            temp_threshold = np.std(temp_diff) * 2
            bee_threshold = np.std(bee_diff) * 2
            
            temp_changes = region_data['year'].iloc[2:][np.abs(temp_diff) > temp_threshold].tolist()
            bee_changes = region_data['year'].iloc[2:][np.abs(bee_diff) > bee_threshold].tolist()
            
            change_points[region] = {
                'temperature_changes': temp_changes,
                'bee_abundance_changes': bee_changes
            }
        
        return change_points
    
    def analyze_correlations(self) -> Dict:
        """
        Analisa correla√ß√µes entre vari√°veis clim√°ticas e de abelhas.
        
        Returns:
            Dict: Resultados da an√°lise de correla√ß√£o
        """
        logger.info("Iniciando an√°lise de correla√ß√µes...")
        
        results = {}
        
        # Vari√°veis para an√°lise de correla√ß√£o
        correlation_vars = [
            'temperature', 'precipitation', 'temperature_anomaly', 'precipitation_anomaly',
            'climate_stress_index', 'bee_abundance', 'species_diversity', 
            'honey_production', 'bee_health_index'
        ]
        
        # Matriz de correla√ß√£o geral
        correlation_matrix = self.data[correlation_vars].corr()
        results['overall_correlation'] = correlation_matrix
        
        # Correla√ß√µes por regi√£o
        regional_correlations = {}
        for region in self.data['region'].unique():
            region_data = self.data[self.data['region'] == region]
            regional_corr = region_data[correlation_vars].corr()
            regional_correlations[region] = regional_corr
        
        results['regional_correlations'] = regional_correlations
        
        # An√°lise de lag correlations
        lag_correlations = self._analyze_lag_correlations()
        results['lag_correlations'] = lag_correlations
        
        # Correla√ß√µes significativas
        significant_correlations = self._identify_significant_correlations(correlation_matrix)
        results['significant_correlations'] = significant_correlations
        
        self.results['correlation_analysis'] = results
        logger.info("An√°lise de correla√ß√µes conclu√≠da")
        
        return results
    
    def _analyze_lag_correlations(self) -> Dict:
        """
        Analisa correla√ß√µes com defasagem temporal.
        
        Returns:
            Dict: Correla√ß√µes com lag
        """
        lag_results = {}
        lags = ANALYSIS_CONFIG['CORRELATION']['LAG_ANALYSIS_PERIODS']
        
        for region in self.data['region'].unique():
            region_data = self.data[self.data['region'] == region].sort_values('year')
            
            lag_correlations = {}
            for lag in lags:
                if lag == 0:
                    corr = region_data['temperature'].corr(region_data['bee_abundance'])
                else:
                    if len(region_data) > lag:
                        temp_lagged = region_data['temperature'].iloc[:-lag]
                        bee_current = region_data['bee_abundance'].iloc[lag:]
                        corr = temp_lagged.corr(bee_current)
                    else:
                        corr = np.nan
                
                lag_correlations[f'lag_{lag}'] = corr
            
            lag_results[region] = lag_correlations
        
        return lag_results
    
    def _identify_significant_correlations(self, correlation_matrix: pd.DataFrame) -> List[Dict]:
        """
        Identifica correla√ß√µes estatisticamente significativas.
        
        Args:
            correlation_matrix (pd.DataFrame): Matriz de correla√ß√£o
        
        Returns:
            List[Dict]: Lista de correla√ß√µes significativas
        """
        threshold = ANALYSIS_CONFIG['CORRELATION']['MIN_CORRELATION_THRESHOLD']
        significant = []
        
        for i, var1 in enumerate(correlation_matrix.columns):
            for j, var2 in enumerate(correlation_matrix.columns):
                if i < j:  # Evitar duplicatas
                    corr_value = correlation_matrix.loc[var1, var2]
                    if abs(corr_value) >= threshold:
                        significant.append({
                            'variable_1': var1,
                            'variable_2': var2,
                            'correlation': corr_value,
                            'strength': 'strong' if abs(corr_value) >= 0.7 else 'moderate'
                        })
        
        return sorted(significant, key=lambda x: abs(x['correlation']), reverse=True)
    
    def analyze_geographic_patterns(self) -> Dict:
        """
        Analisa padr√µes geogr√°ficos e espaciais.
        
        Returns:
            Dict: Resultados da an√°lise geogr√°fica
        """
        logger.info("Iniciando an√°lise de padr√µes geogr√°ficos...")
        
        results = {}
        
        # An√°lise por regi√£o
        regional_summary = self.data.groupby('region').agg({
            'temperature': ['mean', 'std', 'min', 'max'],
            'precipitation': ['mean', 'std', 'min', 'max'],
            'bee_abundance': ['mean', 'std', 'min', 'max'],
            'species_diversity': ['mean', 'std', 'min', 'max'],
            'honey_production': ['mean', 'std', 'min', 'max']
        }).round(2)
        
        results['regional_summary'] = regional_summary
        
        # Gradientes latitudinais
        latitudinal_gradients = self._analyze_latitudinal_gradients()
        results['latitudinal_gradients'] = latitudinal_gradients
        
        # Hotspots de mudan√ßa
        change_hotspots = self._identify_change_hotspots()
        results['change_hotspots'] = change_hotspots
        
        self.results['geographic_analysis'] = results
        logger.info("An√°lise geogr√°fica conclu√≠da")
        
        return results
    
    def _analyze_latitudinal_gradients(self) -> Dict:
        """
        Analisa gradientes latitudinais nas vari√°veis.
        
        Returns:
            Dict: Gradientes latitudinais
        """
        # Calcular correla√ß√µes com latitude
        lat_correlations = {}
        variables = ['temperature', 'precipitation', 'bee_abundance', 
                    'species_diversity', 'honey_production']
        
        for var in variables:
            corr = self.data['latitude'].corr(self.data[var])
            lat_correlations[var] = corr
        
        return lat_correlations
    
    def _identify_change_hotspots(self) -> Dict:
        """
        Identifica regi√µes com maiores mudan√ßas.
        
        Returns:
            Dict: Hotspots de mudan√ßa
        """
        hotspots = {}
        
        for region in self.data['region'].unique():
            region_data = self.data[self.data['region'] == region]
            
            # Calcular magnitude de mudan√ßa
            temp_change = region_data['temperature'].max() - region_data['temperature'].min()
            bee_change = region_data['bee_abundance'].max() - region_data['bee_abundance'].min()
            
            hotspots[region] = {
                'temperature_change': temp_change,
                'bee_abundance_change': bee_change,
                'total_change_score': temp_change + bee_change
            }
        
        return hotspots
    
    def generate_summary_report(self) -> str:
        """
        Gera relat√≥rio resumo da an√°lise.
        
        Returns:
            str: Relat√≥rio em formato texto
        """
        logger.info("Gerando relat√≥rio resumo...")
        
        report = []
        report.append("=" * 80)
        report.append("RELAT√ìRIO DE AN√ÅLISE: ABELHAS E MUDAN√áAS CLIM√ÅTICAS")
        report.append("=" * 80)
        report.append(f"Data da an√°lise: {datetime.now().strftime('%d/%m/%Y %H:%M')}")
        report.append(f"Per√≠odo analisado: {self.data['year'].min()} - {self.data['year'].max()}")
        report.append(f"Regi√µes analisadas: {', '.join(self.data['region'].unique())}")
        report.append(f"Total de registros: {len(self.data)}")
        report.append("")
        
        # Resumo dos dados
        report.append("RESUMO DOS DADOS")
        report.append("-" * 40)
        report.append(f"Temperatura m√©dia: {self.data['temperature'].mean():.1f}¬∞C")
        report.append(f"Precipita√ß√£o m√©dia: {self.data['precipitation'].mean():.0f}mm")
        report.append(f"Abund√¢ncia m√©dia de abelhas: {self.data['bee_abundance'].mean():.1f}")
        report.append(f"Diversidade m√©dia de esp√©cies: {self.data['species_diversity'].mean():.1f}")
        report.append(f"Produ√ß√£o m√©dia de mel: {self.data['honey_production'].mean():.1f}kg")
        report.append("")
        
        # Tend√™ncias principais
        if 'temporal_analysis' in self.results:
            report.append("TEND√äNCIAS PRINCIPAIS")
            report.append("-" * 40)
            
            trends = self.results['temporal_analysis']['regional_trends']
            for region, trend_data in trends.items():
                temp_trend = trend_data['temperature_trend']
                bee_trend = trend_data['bee_abundance_trend']
                
                report.append(f"{region}:")
                report.append(f"  - Temperatura: {temp_trend:+.3f}¬∞C/ano")
                report.append(f"  - Abund√¢ncia de abelhas: {bee_trend:+.2f}/ano")
            
            report.append("")
        
        # Correla√ß√µes significativas
        if 'correlation_analysis' in self.results:
            report.append("CORRELA√á√ïES SIGNIFICATIVAS")
            report.append("-" * 40)
            
            sig_corr = self.results['correlation_analysis']['significant_correlations']
            for corr in sig_corr[:5]:  # Top 5
                report.append(f"{corr['variable_1']} ‚Üî {corr['variable_2']}: {corr['correlation']:.3f} ({corr['strength']})")
            
            report.append("")
        
        # Conclus√µes
        report.append("CONCLUS√ïES PRINCIPAIS")
        report.append("-" * 40)
        report.append("1. Observa-se tend√™ncia de aquecimento em todas as regi√µes")
        report.append("2. Decl√≠nio geral na abund√¢ncia de abelhas correlacionado com temperatura")
        report.append("3. Varia√ß√µes regionais significativas nos padr√µes de mudan√ßa")
        report.append("4. Necessidade de monitoramento cont√≠nuo e medidas de conserva√ß√£o")
        report.append("")
        
        report.append("=" * 80)
        
        report_text = "\n".join(report)
        
        # Salvar relat√≥rio
        report_path = RESULTS_DIR / "analysis_summary_report.txt"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_text)
        
        logger.info(f"Relat√≥rio salvo em: {report_path}")
        return report_text
    
    def save_results(self):
        """
        Salva todos os resultados da an√°lise.
        """
        logger.info("Salvando resultados da an√°lise...")
        
        # Salvar dados processados
        self.data.to_csv(PROCESSED_DATA_DIR / "bee_climate_processed.csv", index=False)
        
        # Salvar resultados espec√≠ficos
        for analysis_type, results in self.results.items():
            if isinstance(results, dict):
                # Converter para DataFrame quando poss√≠vel
                if analysis_type == 'correlation_analysis' and 'overall_correlation' in results:
                    results['overall_correlation'].to_csv(
                        RESULTS_DIR / f"{analysis_type}_correlation_matrix.csv"
                    )
        
        logger.info("Resultados salvos com sucesso")
    
    def run_complete_analysis(self, data_path: Optional[str] = None) -> Dict:
        """
        Executa an√°lise completa.
        
        Args:
            data_path (str, optional): Caminho para dados personalizados
        
        Returns:
            Dict: Todos os resultados da an√°lise
        """
        logger.info("Iniciando an√°lise completa...")
        
        # Carregar dados
        self.load_data(data_path)
        
        # Executar todas as an√°lises
        temporal_results = self.analyze_temporal_patterns()
        correlation_results = self.analyze_correlations()
        geographic_results = self.analyze_geographic_patterns()
        
        # Gerar relat√≥rio
        summary_report = self.generate_summary_report()
        
        # Salvar resultados
        self.save_results()
        
        logger.info("An√°lise completa finalizada")
        
        return {
            'temporal_analysis': temporal_results,
            'correlation_analysis': correlation_results,
            'geographic_analysis': geographic_results,
            'summary_report': summary_report,
            'data_summary': {
                'total_records': len(self.data),
                'regions': list(self.data['region'].unique()),
                'year_range': (self.data['year'].min(), self.data['year'].max())
            }
        }

def main():
    """
    Fun√ß√£o principal para executar a an√°lise.
    """
    print("üêù Iniciando An√°lise de Abelhas e Mudan√ßas Clim√°ticas")
    print("=" * 60)
    
    # Criar analisador
    analyzer = BeeClimateAnalyzer()
    
    # Executar an√°lise completa
    results = analyzer.run_complete_analysis()
    
    # Exibir resumo
    print("\nüìä RESUMO DA AN√ÅLISE")
    print("-" * 30)
    print(f"Total de registros analisados: {results['data_summary']['total_records']}")
    print(f"Regi√µes: {', '.join(results['data_summary']['regions'])}")
    print(f"Per√≠odo: {results['data_summary']['year_range'][0]} - {results['data_summary']['year_range'][1]}")
    
    print("\n‚úÖ An√°lise conclu√≠da com sucesso!")
    print(f"üìÅ Resultados salvos em: {RESULTS_DIR}")
    print(f"üìà Gr√°ficos dispon√≠veis em: {IMAGES_DIR}")
    
    return results

if __name__ == "__main__":
    results = main()